{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc1cfac",
   "metadata": {},
   "source": [
    "# Combined full Walkthorough Dashboard\n",
    "\n",
    "\n",
    "### This notebook contains the entire dashboard from the scratch. \n",
    "\n",
    "The following parts are included for any countries which can be selected in the dashboard. \n",
    "* COVID 19 Infection - Confirmed cases, Confirmed rate filtered, , Doubling rate, Doubling time via regression, Doubling rate filtered (Any country can be selected).  \n",
    "* SIR Model to model COVID19 infection - SIR fit of the infection rate for any county (Any country can be selected)\n",
    "* World Map of COVID19 cofirmed cases. (For all the countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4cea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your base path is at: ads_covid-19'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check some parameters\n",
    "## depending where you launch your notebook, the relative path might not work\n",
    "## you should start the notebook server from your base path\n",
    "## when opening the notebook, typically your path will be ../ads_covid-19/notebooks\n",
    "import os\n",
    "if os.path.split(os.getcwd())[-1]=='notebooks':\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "'Your base path is at: '+os.path.split(os.getcwd())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c1cec",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b88798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5d2f9",
   "metadata": {},
   "source": [
    "## Automatic dataset retreival \n",
    "\n",
    "### Source: \n",
    "* John Hopkins dataset from https://github.com/CSSEGISandData/COVID-19.git \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c198e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository exists. No fetch action required.\n"
     ]
    }
   ],
   "source": [
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure. If there is no Repository \n",
    "        not present then clone the data from GitHub.\n",
    "    '''\n",
    "    \n",
    "    if os.path.exists('data/raw/COVID-19/'):\n",
    "        print('Repository exists. No fetch action required.')\n",
    "        git_pull = subprocess.Popen( \"git pull\" ,\n",
    "                             cwd = os.path.dirname('data/raw/COVID-19/' ),\n",
    "                             shell = True,\n",
    "                             stdout = subprocess.PIPE,\n",
    "                             stderr = subprocess.PIPE )\n",
    "        (out, error) = git_pull.communicate()\n",
    "    else:\n",
    "        print('Repository does not exist. Fetch action required.')\n",
    "        git_clone = subprocess.Popen( \"git clone https://github.com/CSSEGISandData/COVID-19.git\" ,\n",
    "                             cwd = os.path.dirname('data/raw/' ),\n",
    "                             shell = True,\n",
    "                             stdout = subprocess.PIPE,\n",
    "                             stderr = subprocess.PIPE )\n",
    "        (out, error) = git_clone.communicate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e879a",
   "metadata": {},
   "source": [
    "## Initial data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d3e99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of rows stored: 227800\n",
      " Latest date is: 2022-05-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "    data_path='data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    time_idx = pd_raw.columns[4:]\n",
    "    df_plot = pd.DataFrame({\n",
    "        'date':time_idx})\n",
    "    df_input_large= pd_raw['Country/Region'].unique()\n",
    "    \n",
    "    for each in df_input_large:\n",
    "        df_plot[each] =np.array(pd_raw[pd_raw['Country/Region']==each].iloc[:,4::].sum(axis=0))\n",
    "    df = df_plot.drop('date', axis=1)\n",
    "    \n",
    "    #Merging the data set over COUNTRY for CODE column for worldmap\n",
    "    df_code = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')\n",
    "    #url=\"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "    #df_code=pd.read_csv(url,sep=',')\n",
    "    world_raw =  pd.DataFrame({\"COUNTRY\" : df_input_large, \"Confirm cases\" :df.iloc[-1]})\n",
    "    world_con = pd.merge(world_raw, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    world_con.to_csv('data/processed/COVID_WorldMap.csv',sep=';',index=False)\n",
    "    \n",
    "     #Continuation of data preparation \n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'COUNTRY',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model_1=pd_data_base.set_index(['state','COUNTRY']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "    pd_relational_model = pd.merge(pd_relational_model_1, df_code, on = \"COUNTRY\").drop('GDP (BILLIONS)', axis=1)\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    \n",
    "    pd_relational_model.to_csv('data/processed/current_03072022_COVID_confirmed_relational.csv',sep=';',index=False)\n",
    "    \n",
    "    #SIR model data preparation\n",
    "    sir_plot = pd.DataFrame({\n",
    "    'date':time_idx})\n",
    "    #sir_plot.head()\n",
    "    sir_arr= pd_raw['Country/Region'].unique()\n",
    "    sir_list = sir_arr.tolist()\n",
    "    for each in sir_list:\n",
    "        sir_plot[each] =np.array(pd_raw[pd_raw['Country/Region']==each].iloc[:,4::].sum(axis=0))\n",
    "    #sir_plot.head()\n",
    "    \n",
    "    #Creating SIR plot for 100+ countries\n",
    "    sir_plot= sir_plot.drop(columns = ['Taiwan*', 'South Sudan', 'Guyana','Haiti', 'Holy See', 'Honduras', 'Hungary', 'Iceland',\n",
    "                                   'Iraq', 'Ireland', 'Israel', 'Italy',\n",
    "       'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya',\n",
    "       'Korea, South', 'Kosovo','Belgium', 'Belize', 'Benin', 'Bhutan',\n",
    "       'Bolivia', 'Bosnia and Herzegovina', 'Botswana',\n",
    "       'Brunei', 'Bulgaria', 'Burkina Faso', 'Burma', 'Burundi',\n",
    "       'Cabo Verde', 'Cambodia', 'Cameroon', 'Canada',\n",
    "       'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n",
    "       'Comoros', 'Congo (Brazzaville)', 'Congo (Kinshasa)', 'Costa Rica',\n",
    "       \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus', 'Czechia', 'Denmark',\n",
    "       'Diamond Princess', 'Djibouti', 'Luxembourg', 'MS Zaandam', 'Madagascar', 'Malawi',\n",
    "       'Malaysia', 'Maldives', 'Mali', 'Malta', 'Mauritania', 'Mauritius',\n",
    "       'Mexico', 'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Morocco',\n",
    "       'Mozambique', 'Namibia', 'Nepal', 'Netherlands', 'New Zealand',\n",
    "       'Nicaragua', 'Niger', 'Panama', 'Papua New Guinea', 'Paraguay',\n",
    "       'Peru', 'Philippines', 'Bahamas', 'Egypt'])\n",
    "    time_idx = [datetime.strptime(each, \"%m/%d/%y\") for each in sir_plot.date] #to convert all the dates into datetime \n",
    "    time_str= [each.strftime('%Y-%m-%d') for each in time_idx] #to convert datetime function to string\n",
    "    #time_str[0:5]\n",
    "    \n",
    "    #Storing the processed data file and sep';' is a seperator [German std]\n",
    "    sir_plot.to_csv('data/processed/COVID_SIR_flat_table_multiplecountries.csv', sep=';',index=False)\n",
    "    \n",
    "    \n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "    print(' Latest date is: '+str(max(pd_relational_model.date)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    store_relational_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57abc5",
   "metadata": {},
   "source": [
    "## Calculations \n",
    "\n",
    "* Part 1: Doubling rate, doubling rate via regression, savgol filter, Rolling regression, Filtered data. \n",
    "* Part 2: SIR modelling, SIR fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16f34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test slope is: [2.]\n",
      "             date state  COUNTRY   confirmed CODE  confirmed_filtered  \\\n",
      "124095 2022-05-16    no  Germany  25818405.0  DEU          25824007.4   \n",
      "124096 2022-05-17    no  Germany  25890456.0  DEU          25877654.8   \n",
      "124097 2022-05-18    no  Germany  25949175.0  DEU          25939316.2   \n",
      "124098 2022-05-19    no  Germany  25998085.0  DEU          25994490.1   \n",
      "124099 2022-05-20    no  Germany  26040460.0  DEU          26049664.0   \n",
      "\n",
      "        confirmed_DR  confirmed_filtered_DR  \n",
      "124095    581.775248             567.692789  \n",
      "124096    326.129907             523.112686  \n",
      "124097    395.901384             448.887269  \n",
      "124098    482.135955             443.995157  \n",
      "124099    569.554837             471.137442  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','COUNTRY']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter is a digital filter that can be applied to a set of digital data points for the purpose of \n",
    "        smoothing the data, that is, to increase the precision of the data without distorting the signal tendency.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[str(column+'_filtered')]=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression is used to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "\n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','COUNTRY',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','COUNTRY',filter_on]].groupby(['state','COUNTRY']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "\n",
    "    pd_JH_data=pd.read_csv('data/processed/current_03072022_COVID_confirmed_relational.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "\n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg.to_csv('data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "    print(pd_result_larg[pd_result_larg['COUNTRY']=='Germany'].tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e096dbc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:46: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "c:\\python37\\lib\\site-packages\\scipy\\integrate\\odepack.py:247: ODEintWarning:\n",
      "\n",
      "Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "\n",
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:72: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "\n",
    "df_input_large=pd.read_csv('data/processed/COVID_SIR_flat_table_multiplecountries.csv',sep=';').iloc[80:]\n",
    "\n",
    "df_all = df_input_large.columns\n",
    "df_all = list(df_all)\n",
    "\n",
    "def SIR_model(SIR,beta,gamma):\n",
    "    ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta: \n",
    "        \n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    S,I,R=SIR\n",
    "    dS_dt=-beta*S*I/N0          #S*I is the \n",
    "    dI_dt=beta*S*I/N0-gamma*I\n",
    "    dR_dt=gamma*I\n",
    "    return([dS_dt,dI_dt,dR_dt])\n",
    "\n",
    "# Functions for SIR model with time step\n",
    "def SIR_model_t(SIR,t,beta,gamma):\n",
    "    ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        t: time step, mandatory for integral.odeint\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta: \n",
    "        \n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    S,I,R=SIR\n",
    "    dS_dt=-beta*S*I/N0          #S*I is the \n",
    "    dI_dt=beta*S*I/N0-gamma*I\n",
    "    dR_dt=gamma*I\n",
    "    return dS_dt,dI_dt,dR_dt\n",
    "\n",
    "#Function defined for optimize curve fit\n",
    "def fit_odeint(x, beta, gamma):\n",
    "    '''\n",
    "    helper function for the integration\n",
    "    '''\n",
    "    return integrate.odeint(SIR_model_t, (S0, I0, R0), t, args=(beta, gamma))[:,1] # we only would like to get dI\n",
    "\n",
    "#Fitting parameter for SIR model\n",
    "for each in df_all[1:]:\n",
    "    ydata = np.array(df_input_large[each])\n",
    "    t=np.arange(len(ydata))\n",
    "    N0 = 6000000 #max susceptible population\n",
    "\n",
    "    # ensure re-initialization \n",
    "    I0=ydata[0]\n",
    "    S0=N0-I0\n",
    "    R0=0\n",
    "\n",
    "    popt, pcov = optimize.curve_fit(fit_odeint, t, ydata, maxfev = 20000)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    # get the final fitted curve\n",
    "    fitted=fit_odeint(t, *popt).reshape(-1,1)\n",
    "    df_input_large[each +'_fitted'] = fitted \n",
    "    \n",
    "df_input_large.to_csv('data/processed/COVID_fitted_SIR_flat_table.csv', sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431a7442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Antarctica</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Uruguay_fitted</th>\n",
       "      <th>Uzbekistan_fitted</th>\n",
       "      <th>Vanuatu_fitted</th>\n",
       "      <th>Venezuela_fitted</th>\n",
       "      <th>Vietnam_fitted</th>\n",
       "      <th>West Bank and Gaza_fitted</th>\n",
       "      <th>Winter Olympics 2022_fitted</th>\n",
       "      <th>Yemen_fitted</th>\n",
       "      <th>Zambia_fitted</th>\n",
       "      <th>Zimbabwe_fitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4/11/20</td>\n",
       "      <td>521</td>\n",
       "      <td>433</td>\n",
       "      <td>1825</td>\n",
       "      <td>601</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1975</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4/12/20</td>\n",
       "      <td>555</td>\n",
       "      <td>446</td>\n",
       "      <td>1914</td>\n",
       "      <td>638</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2142</td>\n",
       "      <td>1013</td>\n",
       "      <td>...</td>\n",
       "      <td>504.971987</td>\n",
       "      <td>775.555978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.001173</td>\n",
       "      <td>259.200716</td>\n",
       "      <td>271.830362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.016967</td>\n",
       "      <td>40.439220</td>\n",
       "      <td>14.143415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4/13/20</td>\n",
       "      <td>607</td>\n",
       "      <td>467</td>\n",
       "      <td>1983</td>\n",
       "      <td>646</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2208</td>\n",
       "      <td>1039</td>\n",
       "      <td>...</td>\n",
       "      <td>508.937644</td>\n",
       "      <td>784.207228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.141625</td>\n",
       "      <td>260.395723</td>\n",
       "      <td>275.715456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.034223</td>\n",
       "      <td>40.882993</td>\n",
       "      <td>14.288266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4/14/20</td>\n",
       "      <td>665</td>\n",
       "      <td>475</td>\n",
       "      <td>2070</td>\n",
       "      <td>659</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2277</td>\n",
       "      <td>1067</td>\n",
       "      <td>...</td>\n",
       "      <td>512.896035</td>\n",
       "      <td>792.954808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.425022</td>\n",
       "      <td>261.584839</td>\n",
       "      <td>279.656063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.051771</td>\n",
       "      <td>41.331360</td>\n",
       "      <td>14.434565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4/15/20</td>\n",
       "      <td>770</td>\n",
       "      <td>494</td>\n",
       "      <td>2160</td>\n",
       "      <td>673</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2443</td>\n",
       "      <td>1111</td>\n",
       "      <td>...</td>\n",
       "      <td>516.846210</td>\n",
       "      <td>801.799786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.855113</td>\n",
       "      <td>262.767881</td>\n",
       "      <td>283.652975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069617</td>\n",
       "      <td>41.784362</td>\n",
       "      <td>14.582328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  Afghanistan  Albania  Algeria  Andorra  Angola  Antarctica  \\\n",
       "80  4/11/20          521      433     1825      601      19           0   \n",
       "81  4/12/20          555      446     1914      638      19           0   \n",
       "82  4/13/20          607      467     1983      646      19           0   \n",
       "83  4/14/20          665      475     2070      659      19           0   \n",
       "84  4/15/20          770      494     2160      673      19           0   \n",
       "\n",
       "    Antigua and Barbuda  Argentina  Armenia  ...  Uruguay_fitted  \\\n",
       "80                   21       1975      967  ...      501.000000   \n",
       "81                   21       2142     1013  ...      504.971987   \n",
       "82                   23       2208     1039  ...      508.937644   \n",
       "83                   23       2277     1067  ...      512.896035   \n",
       "84                   23       2443     1111  ...      516.846210   \n",
       "\n",
       "    Uzbekistan_fitted  Vanuatu_fitted  Venezuela_fitted  Vietnam_fitted  \\\n",
       "80         767.000000             0.0        175.000000      258.000000   \n",
       "81         775.555978             0.0        180.001173      259.200716   \n",
       "82         784.207228             0.0        185.141625      260.395723   \n",
       "83         792.954808             0.0        190.425022      261.584839   \n",
       "84         801.799786             0.0        195.855113      262.767881   \n",
       "\n",
       "    West Bank and Gaza_fitted  Winter Olympics 2022_fitted  Yemen_fitted  \\\n",
       "80                 268.000000                          0.0      1.000000   \n",
       "81                 271.830362                          0.0      1.016967   \n",
       "82                 275.715456                          0.0      1.034223   \n",
       "83                 279.656063                          0.0      1.051771   \n",
       "84                 283.652975                          0.0      1.069617   \n",
       "\n",
       "    Zambia_fitted  Zimbabwe_fitted  \n",
       "80      40.000000        14.000000  \n",
       "81      40.439220        14.143415  \n",
       "82      40.882993        14.288266  \n",
       "83      41.331360        14.434565  \n",
       "84      41.784362        14.582328  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e8485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_large = pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "df = pd.read_csv('data/processed/COVID_WorldMap.csv',sep=';')\n",
    "df_input_sir = pd.read_csv('data/processed/COVID_fitted_SIR_flat_table.csv',sep=';')\n",
    "df_all = df_input_sir.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9439c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>Andorra</th>\n",
       "      <th>Angola</th>\n",
       "      <th>Antarctica</th>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Armenia</th>\n",
       "      <th>...</th>\n",
       "      <th>Uruguay_fitted</th>\n",
       "      <th>Uzbekistan_fitted</th>\n",
       "      <th>Vanuatu_fitted</th>\n",
       "      <th>Venezuela_fitted</th>\n",
       "      <th>Vietnam_fitted</th>\n",
       "      <th>West Bank and Gaza_fitted</th>\n",
       "      <th>Winter Olympics 2022_fitted</th>\n",
       "      <th>Yemen_fitted</th>\n",
       "      <th>Zambia_fitted</th>\n",
       "      <th>Zimbabwe_fitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5/16/22</td>\n",
       "      <td>179321</td>\n",
       "      <td>275621</td>\n",
       "      <td>265823</td>\n",
       "      <td>42156</td>\n",
       "      <td>99287</td>\n",
       "      <td>11</td>\n",
       "      <td>7795</td>\n",
       "      <td>9135308</td>\n",
       "      <td>422917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161408</td>\n",
       "      <td>186836.830414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>1.233529</td>\n",
       "      <td>493305.176224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6459.388467</td>\n",
       "      <td>9.703746</td>\n",
       "      <td>39.095980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5/17/22</td>\n",
       "      <td>179328</td>\n",
       "      <td>275688</td>\n",
       "      <td>265828</td>\n",
       "      <td>42156</td>\n",
       "      <td>99287</td>\n",
       "      <td>11</td>\n",
       "      <td>7795</td>\n",
       "      <td>9135308</td>\n",
       "      <td>422917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159104</td>\n",
       "      <td>185985.116336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1.220864</td>\n",
       "      <td>490733.073457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6383.467642</td>\n",
       "      <td>9.594886</td>\n",
       "      <td>38.718165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>5/18/22</td>\n",
       "      <td>179477</td>\n",
       "      <td>275732</td>\n",
       "      <td>265834</td>\n",
       "      <td>42572</td>\n",
       "      <td>99287</td>\n",
       "      <td>11</td>\n",
       "      <td>7855</td>\n",
       "      <td>9135308</td>\n",
       "      <td>422917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156834</td>\n",
       "      <td>185131.325340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>1.208329</td>\n",
       "      <td>488156.328256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6308.065481</td>\n",
       "      <td>9.487233</td>\n",
       "      <td>38.343758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>5/19/22</td>\n",
       "      <td>179597</td>\n",
       "      <td>275732</td>\n",
       "      <td>265841</td>\n",
       "      <td>42572</td>\n",
       "      <td>99287</td>\n",
       "      <td>11</td>\n",
       "      <td>7910</td>\n",
       "      <td>9135308</td>\n",
       "      <td>422917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154596</td>\n",
       "      <td>184275.556515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.195922</td>\n",
       "      <td>485575.297555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6233.189193</td>\n",
       "      <td>9.380774</td>\n",
       "      <td>37.972731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>5/20/22</td>\n",
       "      <td>179624</td>\n",
       "      <td>275732</td>\n",
       "      <td>265847</td>\n",
       "      <td>42572</td>\n",
       "      <td>99287</td>\n",
       "      <td>11</td>\n",
       "      <td>7910</td>\n",
       "      <td>9135308</td>\n",
       "      <td>422917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152389</td>\n",
       "      <td>183417.908152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>1.183642</td>\n",
       "      <td>482990.333879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6158.845620</td>\n",
       "      <td>9.275495</td>\n",
       "      <td>37.605060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Afghanistan  Albania  Algeria  Andorra  Angola  Antarctica  \\\n",
       "765  5/16/22       179321   275621   265823    42156   99287          11   \n",
       "766  5/17/22       179328   275688   265828    42156   99287          11   \n",
       "767  5/18/22       179477   275732   265834    42572   99287          11   \n",
       "768  5/19/22       179597   275732   265841    42572   99287          11   \n",
       "769  5/20/22       179624   275732   265847    42572   99287          11   \n",
       "\n",
       "     Antigua and Barbuda  Argentina  Armenia  ...  Uruguay_fitted  \\\n",
       "765                 7795    9135308   422917  ...        0.161408   \n",
       "766                 7795    9135308   422917  ...        0.159104   \n",
       "767                 7855    9135308   422917  ...        0.156834   \n",
       "768                 7910    9135308   422917  ...        0.154596   \n",
       "769                 7910    9135308   422917  ...        0.152389   \n",
       "\n",
       "     Uzbekistan_fitted  Vanuatu_fitted  Venezuela_fitted  Vietnam_fitted  \\\n",
       "765      186836.830414             0.0          0.000522        1.233529   \n",
       "766      185985.116336             0.0          0.000508        1.220864   \n",
       "767      185131.325340             0.0          0.000494        1.208329   \n",
       "768      184275.556515             0.0          0.000480        1.195922   \n",
       "769      183417.908152             0.0          0.000466        1.183642   \n",
       "\n",
       "     West Bank and Gaza_fitted  Winter Olympics 2022_fitted  Yemen_fitted  \\\n",
       "765              493305.176224                          0.0   6459.388467   \n",
       "766              490733.073457                          0.0   6383.467642   \n",
       "767              488156.328256                          0.0   6308.065481   \n",
       "768              485575.297555                          0.0   6233.189193   \n",
       "769              482990.333879                          0.0   6158.845620   \n",
       "\n",
       "     Zambia_fitted  Zimbabwe_fitted  \n",
       "765       9.703746        39.095980  \n",
       "766       9.594886        38.718165  \n",
       "767       9.487233        38.343758  \n",
       "768       9.380774        37.972731  \n",
       "769       9.275495        37.605060  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input_sir.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a59a1f",
   "metadata": {},
   "source": [
    "## Dashboard Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be333331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CVT\\EDS_SS2022_Salim\\ads_covid-19\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8051/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly import tools\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large = pd.read_csv('data/processed/COVID_final_set.csv',sep=';')\n",
    "df = pd.read_csv('data/processed/COVID_WorldMap.csv',sep=';')\n",
    "#df_input_sir = pd.read_csv('data/processed/COVID_SIR_flat_table_multiplecountries.csv',sep=';')\n",
    "df_input_sir = pd.read_csv('data/processed/COVID_fitted_SIR_flat_table.csv',sep=';')\n",
    "df_all = df_input_sir.columns\n",
    "df_all = list(df_all[:300])\n",
    "\n",
    "'''Dashboard is created by using an external stylesheet named BOOTSTRAP. \n",
    "BOOTSTRAP allows us to divide the dashboard into Rows and columns.\n",
    "COVID-19 dashbord has 5 Rows and 2 columns'''\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "app.title = 'COVID-19 Dashboard'\n",
    "\n",
    "app.layout = html.Div([\n",
    "        \n",
    "        dbc.Row(dbc.Col(html.Div(dcc.Markdown('''\n",
    "                            # Enterprise Data Science: COVID-19 Data Analytics\n",
    "                            Goals of the project:\n",
    "                            * To trace the confirmed cases for all the countries\n",
    "                            * To calculate the doubling rate.\n",
    "                            * To simulate the spread of COVID-19 in Brazil using SIR model and also for 100+ countries.\n",
    "                            * To create a user friendly dashboard, which shows the current count of confirmed cases, doubling rate and SIR model.\n",
    "                            ''')),\n",
    "                        width={'size': 10, 'offset': 1},\n",
    "                        )\n",
    "                ),\n",
    "        \n",
    "        dbc.Row(\n",
    "            [   #Dropdown for Timeline Confirmed and Doubling rate\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown',\n",
    "                            options=[ {'label': each,'value':each} for each in df_input_large['COUNTRY'].unique()],\n",
    "                            value=['US', 'Germany','India'], # which are pre-selected\n",
    "                            multi= True),\n",
    "                        width={'size': 5, \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                #Dropdown for SIR model\n",
    "                dbc.Col(dcc.Dropdown(\n",
    "                            id='country_dropdown_sir',\n",
    "                            options=[ {'label': each,'value':each} for each in df_all[1:]],\n",
    "                            value='Brazil', # which are pre-selected\n",
    "                            multi= False\n",
    "                            ),\n",
    "                        width={'size': 5, \"offset\": 2, 'order': 'second'}\n",
    "                        ),\n",
    "                ], className=\"g-0\"\n",
    "        ),\n",
    "    \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                        dcc.Dropdown(\n",
    "                            id='doubling_time',\n",
    "                            options=[\n",
    "                                {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "                                {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "                                {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                                {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'}\n",
    "                            ],\n",
    "                            value='confirmed',\n",
    "                            multi=False\n",
    "                            ),\n",
    "                        width={'size': 3, \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                \n",
    "                \n",
    "                ], \n",
    "        ),\n",
    "                \n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph( \n",
    "                            id='main_window_slope'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "                \n",
    "                dbc.Col(dcc.Graph(\n",
    "                            id='SIR_model'\n",
    "                            ),\n",
    "                        width=6, md={'size': 5,  \"offset\": 1, 'order': 'last'}\n",
    "                        ),\n",
    "            ]\n",
    "        ),\n",
    "        dbc.Row(\n",
    "                dbc.Col(dcc.Graph(id = \"World_map\",\n",
    "                              figure = go.Figure(data = [go.Choropleth(\n",
    "                                        locations = df['CODE'],\n",
    "                                        z = df['Confirm cases'],\n",
    "                                        text = df['COUNTRY'],\n",
    "                                        colorscale = 'Blues',\n",
    "                                        autocolorscale=False,\n",
    "                                        reversescale=False,\n",
    "                                        marker_line_color='darkgray',\n",
    "                                        marker_line_width=0.5,\n",
    "                                        colorbar_title = 'Confirmed cases'\n",
    "                                        )],\n",
    "                                        layout = go.Layout(\n",
    "                                        title_text='COVID 19 WORLD MAP',\n",
    "                                        height=1300,\n",
    "                                        autosize = True,\n",
    "                                        geo=dict(\n",
    "                                            showframe=False,\n",
    "                                            showcoastlines=False,\n",
    "                                            projection_type='equirectangular'\n",
    "                                        ))\n",
    "                                     ),\n",
    "                              \n",
    "                              ),\n",
    "                        width=12, md={'size': 12,  \"offset\": 0, 'order': 'first'}\n",
    "                        ),\n",
    "         )\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_dropdown', 'value'),\n",
    "    Input('doubling_time', 'value')])\n",
    "\n",
    "def update_figure(country_list,show_doubling):\n",
    "\n",
    "\n",
    "    if 'DR' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['COUNTRY']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','COUNTRY','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['COUNTRY','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        traces.append(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each\n",
    "                        )\n",
    "                )\n",
    "\n",
    "    return {\n",
    "            'data': traces,\n",
    "            'layout': dict (\n",
    "                height=900,\n",
    "\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                                             },\n",
    "\n",
    "                yaxis=my_yaxis\n",
    "        ) \n",
    "    }\n",
    "\n",
    "@app.callback(\n",
    "    Output('SIR_model', 'figure'),\n",
    "    [Input('country_dropdown_sir', 'value')])\n",
    "\n",
    "def SIR_fig(con_input):\n",
    "    df= df_input_sir\n",
    "   \n",
    "    \n",
    "    for i in df[1:]:\n",
    "        data = []\n",
    "        trace = go.Scatter(x=df_input_sir.date,\n",
    "                        y=df[con_input],\n",
    "                        mode='lines+markers',\n",
    "                        name = con_input)\n",
    "        data.append(trace)\n",
    "        \n",
    "        trace_fitted = go.Scatter(x=df.date,\n",
    "                        y=df[con_input +'_fitted'], \n",
    "                        mode='lines+markers',\n",
    "                        name=con_input+'_fitted')\n",
    "        data.append(trace_fitted)\n",
    "        \n",
    "        \n",
    "            \n",
    "    return {'data': data,\n",
    "            'layout' : dict(\n",
    "                height=900,\n",
    "                title= 'SIR model',\n",
    "                xaxis={'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "                yaxis={'type':\"log\",\n",
    "                       'range':'[1.1,5.5]'\n",
    "                      }\n",
    "                \n",
    "            )\n",
    "        }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, port= 8051, use_reloader=False)             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
